{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting with LightGBM\n",
    "- Using Sklearn and MLflow\n",
    "- Iterative Multi-step Forecasting (for now)  \n",
    "\n",
    "\n",
    "Beginning with interable model where we can assess how much variability is explained by different features, then we will build deep learning models and compare the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "# import optuna\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import lightgbm as lgb\n",
    "# import os\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import TimeSeriesSplit \n",
    "# from skopt import BayesSearchCV\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Give url for local mlflow server\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "\n",
    "# Multiple outputs per notebook cell\n",
    "%config InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "# random_state for different processes\n",
    "RANDOM_STATE = 221\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "- Creating train/test and validation sets, then ensure windows are correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensure validation set is last 7 days; min date: 2019-04-23 00:00:00+00:00, max date: 2019-04-30 00:00:00+00:00\n",
      "Ensure train/test set excludes last 7 days; min date: 2015-01-01 00:00:00+00:00, max date: 2019-04-22 23:45:00+00:00\n",
      "Ensure validation set is last 7 days; min date: 2019-04-23 00:00:00+00:00, max date: 2019-04-30 00:00:00+00:00\n",
      "Ensure train/test set excludes last 7 days; min date: 2015-01-01 00:00:00+00:00, max date: 2019-04-22 23:00:00+00:00\n"
     ]
    }
   ],
   "source": [
    "cd = Path.cwd()\n",
    "data_dir = str(cd.parents[1])\n",
    "upsampled = data_dir + '/datasets/country_energy/load_wthr_downsample.pickle'\n",
    "downsampled = data_dir + '/datasets/country_energy/load_wthr_upsample.pickle'\n",
    "\n",
    "# Xu - upsampled\n",
    "with open(upsampled, 'rb') as f:\n",
    "    Xu = pickle.load(f)\n",
    "\n",
    "# Xd - downsampled\n",
    "with open(downsampled, 'rb') as f:\n",
    "    Xd = pickle.load(f)\n",
    "\n",
    "# Create test/train and validation set. Ensure dates are correct\n",
    "validation_u = Xu.loc[Xu['day'] > (Xu['day'].max() - pd.to_timedelta('8day'))] # 8 days is selected because last day 2019-4-30 has 0 hours\n",
    "Xu = Xu.loc[Xu['day'] < (Xu['day'].max() - pd.to_timedelta('7day'))]\n",
    "print(f'Ensure validation set is last 7 days; min date: {validation_u.index.min()}, max date: {validation_u.index.max()}')\n",
    "print(f'Ensure train/test set excludes last 7 days; min date: {Xu.index.min()}, max date: {Xu.index.max()}')\n",
    "\n",
    "validation_d = Xd.loc[Xd['day'] > (Xd['day'].max() - pd.to_timedelta('8day'))]\n",
    "Xd = Xd.loc[Xd['day'] < (Xd['day'].max() - pd.to_timedelta('7day'))]\n",
    "print(f'Ensure validation set is last 7 days; min date: {validation_d.index.min()}, max date: {validation_d.index.max()}')\n",
    "print(f'Ensure train/test set excludes last 7 days; min date: {Xd.index.min()}, max date: {Xd.index.max()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare Data for Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "utc_timestamp",
         "rawType": "datetime64[ns, UTC]",
         "type": "unknown"
        },
        {
         "name": "day",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "day_ordinal",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "year",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "week_of_year",
         "rawType": "Float64",
         "type": "float"
        },
        {
         "name": "month",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hour",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "country",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "is_weekend",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "is_holiday",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "temperature",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "radi_direct",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "radi_diffuse",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mean_temp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "max_temp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "min_temp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hdd",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "cdd",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "temperature_lag1_days",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "temperature_rollmean1_days",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "temperature_lag2_days",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "temperature_rollmean2_days",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "temperature_lag7_days",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "temperature_rollmean7_days",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "temperature_lag14_days",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "temperature_rollmean14_days",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "cfaadf99-0cda-47f2-9f81-589adc4ddae9",
       "rows": [
        [
         "2015-01-01 00:00:00+00:00",
         "2015-01-01",
         "735599.0",
         "2015.0",
         "1.0",
         "1.0",
         "0.0",
         "DE",
         "0.0",
         "1.0",
         "-0.981",
         "0.0",
         "0.0",
         "-1.1195347222222223",
         "3.298",
         "-8.399",
         "1",
         "0",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "2015-01-01 01:00:00+00:00",
         "2015-01-01",
         "735599.0",
         "2015.0",
         "1.0",
         "1.0",
         "1.0",
         "DE",
         "0.0",
         "1.0",
         "-1.035",
         "0.0",
         "0.0",
         "-1.1195347222222223",
         "3.298",
         "-8.399",
         "1",
         "0",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "2015-01-01 02:00:00+00:00",
         "2015-01-01",
         "735599.0",
         "2015.0",
         "1.0",
         "1.0",
         "2.0",
         "DE",
         "0.0",
         "1.0",
         "-1.109",
         "0.0",
         "0.0",
         "-1.1195347222222223",
         "3.298",
         "-8.399",
         "1",
         "0",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "2015-01-01 03:00:00+00:00",
         "2015-01-01",
         "735599.0",
         "2015.0",
         "1.0",
         "1.0",
         "3.0",
         "DE",
         "0.0",
         "1.0",
         "-1.166",
         "0.0",
         "0.0",
         "-1.1195347222222223",
         "3.298",
         "-8.399",
         "1",
         "0",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "2015-01-01 04:00:00+00:00",
         "2015-01-01",
         "735599.0",
         "2015.0",
         "1.0",
         "1.0",
         "4.0",
         "DE",
         "0.0",
         "1.0",
         "-1.226",
         "0.0",
         "0.0",
         "-1.1195347222222223",
         "3.298",
         "-8.399",
         "1",
         "0",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ]
       ],
       "shape": {
        "columns": 25,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>day_ordinal</th>\n",
       "      <th>year</th>\n",
       "      <th>week_of_year</th>\n",
       "      <th>month</th>\n",
       "      <th>hour</th>\n",
       "      <th>country</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>temperature</th>\n",
       "      <th>...</th>\n",
       "      <th>hdd</th>\n",
       "      <th>cdd</th>\n",
       "      <th>temperature_lag1_days</th>\n",
       "      <th>temperature_rollmean1_days</th>\n",
       "      <th>temperature_lag2_days</th>\n",
       "      <th>temperature_rollmean2_days</th>\n",
       "      <th>temperature_lag7_days</th>\n",
       "      <th>temperature_rollmean7_days</th>\n",
       "      <th>temperature_lag14_days</th>\n",
       "      <th>temperature_rollmean14_days</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>utc_timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-01 00:00:00+00:00</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>735599.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.981</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 01:00:00+00:00</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>735599.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>DE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.035</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 02:00:00+00:00</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>735599.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>DE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.109</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 03:00:00+00:00</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>735599.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>DE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.166</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 04:00:00+00:00</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>735599.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>DE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.226</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  day  day_ordinal    year  week_of_year  \\\n",
       "utc_timestamp                                                              \n",
       "2015-01-01 00:00:00+00:00  2015-01-01     735599.0  2015.0           1.0   \n",
       "2015-01-01 01:00:00+00:00  2015-01-01     735599.0  2015.0           1.0   \n",
       "2015-01-01 02:00:00+00:00  2015-01-01     735599.0  2015.0           1.0   \n",
       "2015-01-01 03:00:00+00:00  2015-01-01     735599.0  2015.0           1.0   \n",
       "2015-01-01 04:00:00+00:00  2015-01-01     735599.0  2015.0           1.0   \n",
       "\n",
       "                           month  hour country  is_weekend  is_holiday  \\\n",
       "utc_timestamp                                                            \n",
       "2015-01-01 00:00:00+00:00    1.0   0.0      DE         0.0         1.0   \n",
       "2015-01-01 01:00:00+00:00    1.0   1.0      DE         0.0         1.0   \n",
       "2015-01-01 02:00:00+00:00    1.0   2.0      DE         0.0         1.0   \n",
       "2015-01-01 03:00:00+00:00    1.0   3.0      DE         0.0         1.0   \n",
       "2015-01-01 04:00:00+00:00    1.0   4.0      DE         0.0         1.0   \n",
       "\n",
       "                           temperature  ...  hdd  cdd  temperature_lag1_days  \\\n",
       "utc_timestamp                           ...                                    \n",
       "2015-01-01 00:00:00+00:00       -0.981  ...    1    0                    NaN   \n",
       "2015-01-01 01:00:00+00:00       -1.035  ...    1    0                    NaN   \n",
       "2015-01-01 02:00:00+00:00       -1.109  ...    1    0                    NaN   \n",
       "2015-01-01 03:00:00+00:00       -1.166  ...    1    0                    NaN   \n",
       "2015-01-01 04:00:00+00:00       -1.226  ...    1    0                    NaN   \n",
       "\n",
       "                           temperature_rollmean1_days  temperature_lag2_days  \\\n",
       "utc_timestamp                                                                  \n",
       "2015-01-01 00:00:00+00:00                         NaN                    NaN   \n",
       "2015-01-01 01:00:00+00:00                         NaN                    NaN   \n",
       "2015-01-01 02:00:00+00:00                         NaN                    NaN   \n",
       "2015-01-01 03:00:00+00:00                         NaN                    NaN   \n",
       "2015-01-01 04:00:00+00:00                         NaN                    NaN   \n",
       "\n",
       "                           temperature_rollmean2_days  temperature_lag7_days  \\\n",
       "utc_timestamp                                                                  \n",
       "2015-01-01 00:00:00+00:00                         NaN                    NaN   \n",
       "2015-01-01 01:00:00+00:00                         NaN                    NaN   \n",
       "2015-01-01 02:00:00+00:00                         NaN                    NaN   \n",
       "2015-01-01 03:00:00+00:00                         NaN                    NaN   \n",
       "2015-01-01 04:00:00+00:00                         NaN                    NaN   \n",
       "\n",
       "                           temperature_rollmean7_days  temperature_lag14_days  \\\n",
       "utc_timestamp                                                                   \n",
       "2015-01-01 00:00:00+00:00                         NaN                     NaN   \n",
       "2015-01-01 01:00:00+00:00                         NaN                     NaN   \n",
       "2015-01-01 02:00:00+00:00                         NaN                     NaN   \n",
       "2015-01-01 03:00:00+00:00                         NaN                     NaN   \n",
       "2015-01-01 04:00:00+00:00                         NaN                     NaN   \n",
       "\n",
       "                           temperature_rollmean14_days  \n",
       "utc_timestamp                                           \n",
       "2015-01-01 00:00:00+00:00                          NaN  \n",
       "2015-01-01 01:00:00+00:00                          NaN  \n",
       "2015-01-01 02:00:00+00:00                          NaN  \n",
       "2015-01-01 03:00:00+00:00                          NaN  \n",
       "2015-01-01 04:00:00+00:00                          NaN  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "utc_timestamp",
         "rawType": "datetime64[ns, UTC]",
         "type": "unknown"
        },
        {
         "name": "day",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "day_ordinal",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "year",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "week_of_year",
         "rawType": "Float64",
         "type": "float"
        },
        {
         "name": "month",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hour",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "country",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "is_weekend",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "is_holiday",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "temperature",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "radi_direct",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "radi_diffuse",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mean_temp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "max_temp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "min_temp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hdd",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "cdd",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "temperature_lag1_days",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "temperature_rollmean1_days",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "temperature_lag2_days",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "temperature_rollmean2_days",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "temperature_lag7_days",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "temperature_rollmean7_days",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "temperature_lag14_days",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "temperature_rollmean14_days",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "a5d4ad72-a56a-4a90-bb2f-d6a09aa68d1d",
       "rows": [
        [
         "2015-01-02 00:00:00+00:00",
         "2015-01-02",
         "735600.0",
         "2015.0",
         "1.0",
         "1.0",
         "0.0",
         "DE",
         "0.0",
         "0.0",
         "-0.49",
         "0.0",
         "0.0",
         "1.637138888888889",
         "7.643",
         "-3.865",
         "1",
         "0",
         "-0.981",
         "-2.5132499999999998",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "2015-01-02 01:00:00+00:00",
         "2015-01-02",
         "735600.0",
         "2015.0",
         "1.0",
         "1.0",
         "1.0",
         "DE",
         "0.0",
         "0.0",
         "-0.432",
         "0.0",
         "0.0",
         "1.637138888888889",
         "7.643",
         "-3.865",
         "1",
         "0",
         "-1.035",
         "-2.3316666666666666",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "2015-01-02 02:00:00+00:00",
         "2015-01-02",
         "735600.0",
         "2015.0",
         "1.0",
         "1.0",
         "2.0",
         "DE",
         "0.0",
         "0.0",
         "-0.326",
         "0.0",
         "0.0",
         "1.637138888888889",
         "7.643",
         "-3.865",
         "1",
         "0",
         "-1.109",
         "-2.1437916666666665",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "2015-01-02 03:00:00+00:00",
         "2015-01-02",
         "735600.0",
         "2015.0",
         "1.0",
         "1.0",
         "3.0",
         "DE",
         "0.0",
         "0.0",
         "-0.17",
         "0.0",
         "0.0",
         "1.637138888888889",
         "7.643",
         "-3.865",
         "1",
         "0",
         "-1.166",
         "-1.9621666666666666",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "2015-01-02 04:00:00+00:00",
         "2015-01-02",
         "735600.0",
         "2015.0",
         "1.0",
         "1.0",
         "4.0",
         "DE",
         "0.0",
         "0.0",
         "-0.016",
         "0.0",
         "0.0",
         "1.637138888888889",
         "7.643",
         "-3.865",
         "1",
         "0",
         "-1.226",
         "-1.8023333333333333",
         null,
         null,
         null,
         null,
         null,
         null
        ]
       ],
       "shape": {
        "columns": 25,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>day_ordinal</th>\n",
       "      <th>year</th>\n",
       "      <th>week_of_year</th>\n",
       "      <th>month</th>\n",
       "      <th>hour</th>\n",
       "      <th>country</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>temperature</th>\n",
       "      <th>...</th>\n",
       "      <th>hdd</th>\n",
       "      <th>cdd</th>\n",
       "      <th>temperature_lag1_days</th>\n",
       "      <th>temperature_rollmean1_days</th>\n",
       "      <th>temperature_lag2_days</th>\n",
       "      <th>temperature_rollmean2_days</th>\n",
       "      <th>temperature_lag7_days</th>\n",
       "      <th>temperature_rollmean7_days</th>\n",
       "      <th>temperature_lag14_days</th>\n",
       "      <th>temperature_rollmean14_days</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>utc_timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-02 00:00:00+00:00</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>735600.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.490</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.981</td>\n",
       "      <td>-2.513250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-02 01:00:00+00:00</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>735600.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>DE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.432</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.035</td>\n",
       "      <td>-2.331667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-02 02:00:00+00:00</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>735600.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>DE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.326</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.109</td>\n",
       "      <td>-2.143792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-02 03:00:00+00:00</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>735600.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>DE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.170</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.166</td>\n",
       "      <td>-1.962167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-02 04:00:00+00:00</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>735600.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>DE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.226</td>\n",
       "      <td>-1.802333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  day  day_ordinal    year  week_of_year  \\\n",
       "utc_timestamp                                                              \n",
       "2015-01-02 00:00:00+00:00  2015-01-02     735600.0  2015.0           1.0   \n",
       "2015-01-02 01:00:00+00:00  2015-01-02     735600.0  2015.0           1.0   \n",
       "2015-01-02 02:00:00+00:00  2015-01-02     735600.0  2015.0           1.0   \n",
       "2015-01-02 03:00:00+00:00  2015-01-02     735600.0  2015.0           1.0   \n",
       "2015-01-02 04:00:00+00:00  2015-01-02     735600.0  2015.0           1.0   \n",
       "\n",
       "                           month  hour country  is_weekend  is_holiday  \\\n",
       "utc_timestamp                                                            \n",
       "2015-01-02 00:00:00+00:00    1.0   0.0      DE         0.0         0.0   \n",
       "2015-01-02 01:00:00+00:00    1.0   1.0      DE         0.0         0.0   \n",
       "2015-01-02 02:00:00+00:00    1.0   2.0      DE         0.0         0.0   \n",
       "2015-01-02 03:00:00+00:00    1.0   3.0      DE         0.0         0.0   \n",
       "2015-01-02 04:00:00+00:00    1.0   4.0      DE         0.0         0.0   \n",
       "\n",
       "                           temperature  ...  hdd  cdd  temperature_lag1_days  \\\n",
       "utc_timestamp                           ...                                    \n",
       "2015-01-02 00:00:00+00:00       -0.490  ...    1    0                 -0.981   \n",
       "2015-01-02 01:00:00+00:00       -0.432  ...    1    0                 -1.035   \n",
       "2015-01-02 02:00:00+00:00       -0.326  ...    1    0                 -1.109   \n",
       "2015-01-02 03:00:00+00:00       -0.170  ...    1    0                 -1.166   \n",
       "2015-01-02 04:00:00+00:00       -0.016  ...    1    0                 -1.226   \n",
       "\n",
       "                           temperature_rollmean1_days  temperature_lag2_days  \\\n",
       "utc_timestamp                                                                  \n",
       "2015-01-02 00:00:00+00:00                   -2.513250                    NaN   \n",
       "2015-01-02 01:00:00+00:00                   -2.331667                    NaN   \n",
       "2015-01-02 02:00:00+00:00                   -2.143792                    NaN   \n",
       "2015-01-02 03:00:00+00:00                   -1.962167                    NaN   \n",
       "2015-01-02 04:00:00+00:00                   -1.802333                    NaN   \n",
       "\n",
       "                           temperature_rollmean2_days  temperature_lag7_days  \\\n",
       "utc_timestamp                                                                  \n",
       "2015-01-02 00:00:00+00:00                         NaN                    NaN   \n",
       "2015-01-02 01:00:00+00:00                         NaN                    NaN   \n",
       "2015-01-02 02:00:00+00:00                         NaN                    NaN   \n",
       "2015-01-02 03:00:00+00:00                         NaN                    NaN   \n",
       "2015-01-02 04:00:00+00:00                         NaN                    NaN   \n",
       "\n",
       "                           temperature_rollmean7_days  temperature_lag14_days  \\\n",
       "utc_timestamp                                                                   \n",
       "2015-01-02 00:00:00+00:00                         NaN                     NaN   \n",
       "2015-01-02 01:00:00+00:00                         NaN                     NaN   \n",
       "2015-01-02 02:00:00+00:00                         NaN                     NaN   \n",
       "2015-01-02 03:00:00+00:00                         NaN                     NaN   \n",
       "2015-01-02 04:00:00+00:00                         NaN                     NaN   \n",
       "\n",
       "                           temperature_rollmean14_days  \n",
       "utc_timestamp                                           \n",
       "2015-01-02 00:00:00+00:00                          NaN  \n",
       "2015-01-02 01:00:00+00:00                          NaN  \n",
       "2015-01-02 02:00:00+00:00                          NaN  \n",
       "2015-01-02 03:00:00+00:00                          NaN  \n",
       "2015-01-02 04:00:00+00:00                          NaN  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "utc_timestamp\n",
       "2015-01-02 12:00:00+00:00    59567.8950\n",
       "2015-01-02 13:00:00+00:00    58561.0800\n",
       "2015-01-02 14:00:00+00:00    58011.8600\n",
       "2015-01-02 15:00:00+00:00    59286.7050\n",
       "2015-01-02 16:00:00+00:00    62207.6925\n",
       "Name: load_actual, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "utc_timestamp\n",
       "2015-01-03 12:00:00+00:00    52905.5625\n",
       "2015-01-03 13:00:00+00:00    51660.2750\n",
       "2015-01-03 14:00:00+00:00    51103.9925\n",
       "2015-01-03 15:00:00+00:00    53047.3625\n",
       "2015-01-03 16:00:00+00:00    56013.8200\n",
       "Name: load_actual, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xd_features = Xd.drop(columns='load_actual') # country, day, hdd, cdd\n",
    "yd = Xd['load_actual']\n",
    "\n",
    "X_train, X_test = Xd_features[0:24], Xd_features[24:36]\n",
    "y_train, y_test = yd[36:60], yd[60:72]\n",
    "\n",
    "X_train.head()\n",
    "X_test.head()\n",
    "y_train.head()\n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective Function (LightGBM) -- consider adding timing param within mlflow (assuming mlflow doesn't already track that)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params, x, y, n_splits=10): # n_splits=10, params, # adjust x, y being the upsample and downsample datasets\n",
    "    \n",
    "    # Time Series splits for cross validation \n",
    "    num_rows_horizon = len(x.loc[x['day'] > (x['day'].max() - pd.to_timedelta('7day'))])\n",
    "    ts_cv = TimeSeriesSplit(n_splits=10, test_size=num_rows_horizon) \n",
    "    folds = []\n",
    "    fold_mae = []\n",
    "    fold_mape = []\n",
    "\n",
    "    # drop unneeded day variable\n",
    "    x = x.drop(columns='day')\n",
    "\n",
    "    # start run with ml flow, record metrics\n",
    "    # try this: mlflow.autolog()\n",
    "    with mlflow.start_run(nested=False): #nested=True\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        # Dataset splits for cross-validation\n",
    "        for i, (train_idx, test_idx) in enumerate(ts_cv.split(x)):\n",
    "            X_train, X_test = x.iloc[train_idx], x.iloc[test_idx]\n",
    "            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "            # model, model fit, and predictions\n",
    "                # partial w/ params?\n",
    "            model = lgb.LGBMRegressor(\n",
    "                **params, \n",
    "                random_state=RANDOM_STATE, \n",
    "                n_jobs=-1,\n",
    "                early_stopping_round = 5,\n",
    " # early_stopping_min_delta \n",
    "                )  # path_smooth \n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            # loss metrics\n",
    "            mae = mean_absolute_error(y_test, y_pred)\n",
    "            mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "            # record loss metrics for mean\n",
    "            folds.append(i+1)\n",
    "            fold_mae.append(mae)\n",
    "            fold_mape.append(mape)\n",
    "    \n",
    "        # log mean / std of folds\n",
    "        avg_mae = np.mean(fold_mae)\n",
    "        std_mae = np.std(fold_mae)\n",
    "        avg_mape = np.mean(fold_mape)\n",
    "        std_mape = np.std(fold_mape)\n",
    "        mlflow.log_metrics({\n",
    "            'avg_mae': avg_mae,\n",
    "            'std_mae': std_mae,\n",
    "            'avg_mape': avg_mape,\n",
    "            'std_mape': std_mape,   \n",
    "        })\n",
    "\n",
    "        # fold level results\n",
    "        tbl = pd.DataFrame({'folds': folds, \n",
    "                            'mae_per_fold': fold_mae,\n",
    "                            \"mape_per_fold\": fold_mape}).round(4)\n",
    "        mlflow.log_table(data=tbl, artifact_file='results_per_fold.json')\n",
    "        \n",
    "    mlflow.end_run()\n",
    "    return {'avg_mae': avg_mae, 'std_mae': std_mae, 'avg_mape': avg_mape, 'std_mape': std_mape}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Training and Hyperparameter Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/359589701925068288', creation_time=1740264869609, experiment_id='359589701925068288', last_update_time=1740264869609, lifecycle_stage='active', name='Time Series CV Parameter Tuning', tags={}>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006785 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3930\n",
      "[LightGBM] [Info] Number of data points in the train set: 36072, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 9978.581286\n",
      "ðŸƒ View run intrigued-squid-866 at: http://127.0.0.1:5000/#/experiments/359589701925068288/runs/d046f44dd80341c0b2c06f709ef5b53f\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/359589701925068288\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "For early stopping, at least one dataset and eval metric is required for evaluation",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 50\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Parameter search loop - seek to do in parallel\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# BayesSearchCV(\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m#         estimator = LGBMClassifier(),\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m#         random_state = 42 \u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m#     ).fit(x_train, y_train);\u001b[39;00m\n\u001b[0;32m     49\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;66;03m# mlflow may replace this\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXd_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myd\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     51\u001b[0m end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mParams = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: MAE = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_mae\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, MAPE = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_mape\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2%\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Total Runtime = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)    \n",
      "Cell \u001b[1;32mIn[28], line 32\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(params, x, y, n_splits)\u001b[0m\n\u001b[0;32m     23\u001b[0m            \u001b[38;5;66;03m# model, model fit, and predictions\u001b[39;00m\n\u001b[0;32m     24\u001b[0m                \u001b[38;5;66;03m# partial w/ params?\u001b[39;00m\n\u001b[0;32m     25\u001b[0m            model \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mLGBMRegressor(\n\u001b[0;32m     26\u001b[0m                \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams, \n\u001b[0;32m     27\u001b[0m                random_state\u001b[38;5;241m=\u001b[39mRANDOM_STATE, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# early_stopping_min_delta \u001b[39;00m\n\u001b[0;32m     31\u001b[0m                )  \u001b[38;5;66;03m# path_smooth \u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m            \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m            y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     35\u001b[0m            \u001b[38;5;66;03m# loss metrics\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\WulfN\\Python Projects\\venv\\Lib\\site-packages\\lightgbm\\sklearn.py:1398\u001b[0m, in \u001b[0;36mLGBMRegressor.fit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m   1381\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[0;32m   1382\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1383\u001b[0m     X: _LGBM_ScikitMatrixLike,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1395\u001b[0m     init_model: Optional[Union[\u001b[38;5;28mstr\u001b[39m, Path, Booster, LGBMModel]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1396\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLGBMRegressor\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1397\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1398\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1400\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1401\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1402\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1403\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1404\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1405\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1406\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1407\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1411\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1412\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\WulfN\\Python Projects\\venv\\Lib\\site-packages\\lightgbm\\sklearn.py:1049\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m   1046\u001b[0m evals_result: _EvalResultDict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   1047\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[1;32m-> 1049\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1050\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1051\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1052\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1053\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1055\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1056\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1057\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1058\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1060\u001b[0m \u001b[38;5;66;03m# This populates the property self.n_features_, the number of features in the fitted model,\u001b[39;00m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;66;03m# and so should only be set after fitting.\u001b[39;00m\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;66;03m# The related property self._n_features_in, which populates self.n_features_in_,\u001b[39;00m\n\u001b[0;32m   1064\u001b[0m \u001b[38;5;66;03m# is set BEFORE fitting.\u001b[39;00m\n\u001b[0;32m   1065\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster\u001b[38;5;241m.\u001b[39mnum_feature()\n",
      "File \u001b[1;32mc:\\Users\\WulfN\\Python Projects\\venv\\Lib\\site-packages\\lightgbm\\engine.py:332\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    331\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_after_iter:\n\u001b[1;32m--> 332\u001b[0m         \u001b[43mcb\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCallbackEnv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbooster\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m                \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m                \u001b[49m\u001b[43miteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    337\u001b[0m \u001b[43m                \u001b[49m\u001b[43mbegin_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[43m                \u001b[49m\u001b[43mend_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_iteration\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    339\u001b[0m \u001b[43m                \u001b[49m\u001b[43mevaluation_result_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevaluation_result_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m callback\u001b[38;5;241m.\u001b[39mEarlyStopException \u001b[38;5;28;01mas\u001b[39;00m earlyStopException:\n\u001b[0;32m    343\u001b[0m     booster\u001b[38;5;241m.\u001b[39mbest_iteration \u001b[38;5;241m=\u001b[39m earlyStopException\u001b[38;5;241m.\u001b[39mbest_iteration \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\WulfN\\Python Projects\\venv\\Lib\\site-packages\\lightgbm\\callback.py:404\u001b[0m, in \u001b[0;36m_EarlyStoppingCallback.__call__\u001b[1;34m(self, env)\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, env: CallbackEnv) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m env\u001b[38;5;241m.\u001b[39miteration \u001b[38;5;241m==\u001b[39m env\u001b[38;5;241m.\u001b[39mbegin_iteration:\n\u001b[1;32m--> 404\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    405\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menabled:\n\u001b[0;32m    406\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\WulfN\\Python Projects\\venv\\Lib\\site-packages\\lightgbm\\callback.py:328\u001b[0m, in \u001b[0;36m_EarlyStoppingCallback._init\u001b[1;34m(self, env)\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_init\u001b[39m(\u001b[38;5;28mself\u001b[39m, env: CallbackEnv) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m env\u001b[38;5;241m.\u001b[39mevaluation_result_list \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m env\u001b[38;5;241m.\u001b[39mevaluation_result_list \u001b[38;5;241m==\u001b[39m []:\n\u001b[1;32m--> 328\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor early stopping, at least one dataset and eval metric is required for evaluation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    330\u001b[0m     is_dart \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(env\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(alias, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdart\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m alias \u001b[38;5;129;01min\u001b[39;00m _ConfigAliases\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboosting\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m    331\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_dart:\n",
      "\u001b[1;31mValueError\u001b[0m: For early stopping, at least one dataset and eval metric is required for evaluation"
     ]
    }
   ],
   "source": [
    "# Prep data\n",
    "Xd_features = (Xd.loc[Xd['country'] == 'BE']\n",
    "               .drop(columns=['load_actual', 'country']) # hdd cdd\n",
    "               .reset_index(drop=True)) \n",
    "\n",
    "yd = (Xd.loc[Xd.country == 'BE']\n",
    "      .reset_index(drop=True)[['load_actual']])\n",
    "    ### automate to work across countries\n",
    "\n",
    "#### Seek to do param searhc in parallel\n",
    "# Prelim Params\n",
    "# params = {\n",
    "#     'n_estimators': trial.suggest_int('n_estimators', 100, 1000), # adjust\n",
    "#     'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.5),\n",
    "#     'num_leaves': trial.suggest_int('num_leaves', 31, 511), # adjust\n",
    "#     'max_depth': trial.suggest_int('max_depth', 3, 9), # adjust if overfit\n",
    "#     'subsample': trial.suggest_float('subsample', 0.5, 1), # research\n",
    "#     'colsample_bytree': trial.suggest-float('colsample_bytree', 0.7, 1),\n",
    "#     'reg_alpha': trial.suggest_float('reg_alpha', 0, 1),\n",
    "#     'reg_lambda': trial.suggest_float('reg_lambda', 0, 1)\n",
    "# }\n",
    "\n",
    "# simplified params for testing\n",
    "# params = {\n",
    "#     'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.5),\n",
    "#     'reg_alpha': trial.suggest_float('reg_alpha', 0, 1)\n",
    "# }\n",
    "\n",
    "params = {'learning_rate': [0.001],\n",
    "          'reg_alpha': [0.5]}\n",
    "\n",
    "mlflow.end_run() # cancel any existing flows\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    mlflow.set_experiment(\"Time Series CV Parameter Tuning\")\n",
    "    \n",
    "    # Parameter search loop - seek to do in parallel\n",
    "    # BayesSearchCV(\n",
    "    #         estimator = LGBMClassifier(),\n",
    "    #         search_spaces = param_space,\n",
    "    #         scoring = 'accuracy', \n",
    "    #         cv = 1, # cv=None defaults to 3 folds\n",
    "    #         n_iter = 50, \n",
    "    #         n_jobs = -1,\n",
    "    #         return_train_score = True,\n",
    "    #         random_state = 42 \n",
    "    #     ).fit(x_train, y_train);\n",
    "\n",
    "    start = time.time() # mlflow may replace this\n",
    "    results = objective(params, Xd_features, yd) \n",
    "    end = round(time.time() - start, 2)\n",
    "    print(f\"\\n\\nParams = {params}: MAE = {results['avg_mae']:.2f}, MAPE = {results['avg_mape']:.2%}, Total Runtime = {end}\")    \n",
    "\n",
    "\n",
    "    # for params in generate_parameter_combinations(param_grid):  # Implement your grid generator\n",
    "    #     with mlflow.start_run():\n",
    "    #         results = objective(params, X, y)\n",
    "    #         print(f\"Tested {params}: MAE={results['avg_mae']:.2f}, MAPE={results['avg_mape']:.2%}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'avg_mae': 887.8164082561352,\n",
       " 'std_mae': 123.64013095076388,\n",
       " 'avg_mape': 9.279068587006188,\n",
       " 'std_mape': 123.64013095076388}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=37752, step=1)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hypothesis 1: Index values are different for selected country, Belgium\n",
    "# Hypothesis 2: there is not row index value, only utc_timestamp\n",
    "    # both were true\n",
    "\n",
    "# Hypothesis 3:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random string\n",
    "    # ensure if covers mlfflow and other processes\n",
    "\n",
    "# parallelization with mlflow\n",
    "# https://mlflow.org/docs/latest/traditional-ml/hyperparameter-tuning-with-child-runs/notebooks/index.html\n",
    "\n",
    "# study.trials_dataframe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results Graphs (MLflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/20 13:53:40 INFO mlflow.tracking.fluent: Experiment with name 'check-localhost-connection' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/140043457852554855', creation_time=1740084820943, experiment_id='140043457852554855', last_update_time=1740084820943, lifecycle_stage='active', name='check-localhost-connection', tags={}>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run omniscient-cod-280 at: http://127.0.0.1:5000/#/experiments/140043457852554855/runs/b337cbc6f61c4ea7960c2d7baf56f10e\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/140043457852554855\n"
     ]
    }
   ],
   "source": [
    "# Can optuna or MLflow assist in this\n",
    "# mlflow.set_experiment(\"check-localhost-connection\")\n",
    "# mlflow.set_experiment(\"LightGBM Forecasting\")\n",
    "\n",
    "# with mlflow.start_run():\n",
    "#     mlflow.log_metric(\"foo\", 1)\n",
    "#     mlflow.log_metric(\"bar\", 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Importance of Best Model, MAPE, MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Model on final validation set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
