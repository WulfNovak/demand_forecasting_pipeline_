{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "#import optuna\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import lightgbm as lgb\n",
    "import os\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# Set directory for mlflow runs\n",
    "base_dir = str(Path.cwd().parents[1])\n",
    "MLFLOW_TRACKING_URI = base_dir + '/mlflow/load_forecasting_analysis/'\n",
    "os.environ[\"MLFLOW_TRACKING_URI\"] = MLFLOW_TRACKING_URI\n",
    "\n",
    "############################## Activate local web host ##############################\n",
    "# mlflow server --host 127.0.0.1 --port 5000 --backend-store-uri MLFLOW_TRACKING_URI\n",
    "#####################################################################################\n",
    "\n",
    "# Multiple outputs per notebook cell\n",
    "%config InteractiveShell.ast_node_interactivity = 'all'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\WulfN/mlflow/load_forecasting_analysis/'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"MLFLOW_TRACKING_URI\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd = Path.cwd()\n",
    "data_dir = str(cd.parents[1])\n",
    "upsampled = data_dir + '/datasets/country_energy/load_wthr_downsample.pickle'\n",
    "downsampled = data_dir + '/datasets/country_energy/load_wthr_upsample.pickle'\n",
    "\n",
    "# Xu - upsampled\n",
    "with open(upsampled, 'rb') as f:\n",
    "    Xu = pickle.load(f)\n",
    "\n",
    "# Xd - downsampled\n",
    "with open(downsampled, 'rb') as f:\n",
    "    Xd = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare Data for Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Xd.drop(columns='load_actual') # set to x\n",
    "y = Xd['load_actual']\n",
    "\n",
    "ts_cv = TimeSeriesSplit(n_splits=10)\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(ts_cv.split(X)):\n",
    "        print(f\"Fold {i}:\")\n",
    "        print(f\"  Train: index={train_index}\")\n",
    "        print(f\"  Test:  index={test_index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective Function (LightGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, x, y): # n_splits=10, # adjust\n",
    "    \n",
    "    # Prelim Params\n",
    "    # params = {\n",
    "    #     'n_estimators': trial.suggest_int('n_estimators', 100, 1000), # adjust\n",
    "    #     'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.5),\n",
    "    #     'num_leaves': trial.suggest_int('num_leaves', 31, 511), # adjust\n",
    "    #     'max_depth': trial.suggest_int('max_depth', 3, 9), # adjust if overfit\n",
    "    #     'subsample': trial.suggest_float('subsample', 0.5, 1), # research\n",
    "    #     'colsample_bytree': trial.suggest-float('colsample_bytree', 0.7, 1),\n",
    "    #     'reg_alpha': trial.suggest_float('reg_alpha', 0, 1),\n",
    "    #     'reg_lambda': trial.suggest_float('reg_lambda', 0, 1)\n",
    "    # }\n",
    "\n",
    "    # simplified params for testing\n",
    "    params = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.5),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 1)\n",
    "    }\n",
    "\n",
    "    # Consider specifying a param for the number of splits\n",
    "    ts_cv = TimeSeriesSplit(n_splits=10)\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(ts_cv.split(X)):\n",
    "        print(f\"Fold {i}:\")\n",
    "        print(f\"  Train: index={train_index}\")\n",
    "        print(f\"  Test:  index={test_index}\")\n",
    "\n",
    "    # Example splits data and fits models on the different folds\n",
    "    # then stores resulting mae and mape\n",
    "\n",
    "    # Understand timeseriessplit\n",
    "\n",
    "    # Cross val - Is this done by repeatedly calling objective function?\n",
    "\n",
    "    # Parallel processing (if possible) - This may be in the model training section\n",
    "    # https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/004_distributed.html\n",
    "\n",
    "    # Store results metrics (mape, mae)\n",
    "\n",
    "    # Average across cross validated datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Training and Hyperparameter Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random string\n",
    "    # ensure if covers mlfflow and other processes\n",
    "\n",
    "# parallelization with mlflow\n",
    "# https://mlflow.org/docs/latest/traditional-ml/hyperparameter-tuning-with-child-runs/notebooks/index.html\n",
    "\n",
    "# study.trials_dataframe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results Graphs (MLflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/20 13:53:40 INFO mlflow.tracking.fluent: Experiment with name 'check-localhost-connection' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/140043457852554855', creation_time=1740084820943, experiment_id='140043457852554855', last_update_time=1740084820943, lifecycle_stage='active', name='check-localhost-connection', tags={}>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run omniscient-cod-280 at: http://127.0.0.1:5000/#/experiments/140043457852554855/runs/b337cbc6f61c4ea7960c2d7baf56f10e\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/140043457852554855\n"
     ]
    }
   ],
   "source": [
    "# Can optuna or MLflow assist in this\n",
    "# mlflow.set_experiment(\"check-localhost-connection\")\n",
    "# mlflow.set_experiment(\"LightGBM Forecasting\")\n",
    "\n",
    "# with mlflow.start_run():\n",
    "#     mlflow.log_metric(\"foo\", 1)\n",
    "#     mlflow.log_metric(\"bar\", 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Importance of Best Model, MAPE, MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Model on final validation set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
